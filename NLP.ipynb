{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e282d0ff-014c-4d4f-b5f3-a9fff0038770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import polars\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f7a46-db3c-44cf-abab-8caf35b00ffb",
   "metadata": {},
   "source": [
    "# Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "dee0e9d7-c36a-4288-a0e1-a138df33ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Email_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The PRODUCT quality is EXCELLENT!!! üòç Bought o...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>vamshi.kumar@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Worst experience EVER!!! üò° totally disappointe...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>rockstar_99@yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The service was OKAY, nothing special #average</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>data.learner@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I LOVE this product &lt;b&gt;Highly Recommended&lt;/b&gt; üëçüëç</td>\n",
       "      <td>Positive</td>\n",
       "      <td>ml.engineer@outlook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Very poor customer support @supportteam, delay...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>support.user@yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>&lt;p&gt;Average performance&lt;/p&gt; could be BETTER!!!</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>analytics.pro@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Absolutely FANTASTIC!!! üòçüî• #HappyCustomer</td>\n",
       "      <td>Positive</td>\n",
       "      <td>happy.customer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Not worth the money I paid 5000‚Çπ üò†</td>\n",
       "      <td>Negative</td>\n",
       "      <td>budget.buyer@yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>The app works fine BUT sometimes crashes @devteam</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>app.tester@outlook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Great VALUE for money üí∞ Fast delivery on 2024-...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>fast.delivery@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Terrible packaging!!! damaged product üò°üò°</td>\n",
       "      <td>Negative</td>\n",
       "      <td>angry.user@yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>The product does WHAT it claims &lt;xml&gt;verified&lt;...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>verified.buyer@outlook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Amazing experience üòä Will BUY again!!!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>repeat.customer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Completely USELESS and frustrating üò§üò§</td>\n",
       "      <td>Negative</td>\n",
       "      <td>frustrated.user@yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Neither good NOR bad, just okay... ü§∑</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>neutral.reviewer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Customer service was VERY helpful &amp; polite @he...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>polite.customer@outlook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Bad quality material!!! broke within 3 days üòû</td>\n",
       "      <td>Negative</td>\n",
       "      <td>quality.issue@yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>The design is decent BUT functionality is LIMI...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>design.reviewer@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Extremely satisfied with the purchase üòç #Satis...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>satisfied.user@outlook.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Regret buying this üò° Very disappointing!!! Ord...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>disappointed.buyer@yahoo.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Review_ID                                        Review_Text Sentiment  \\\n",
       "0           1  The PRODUCT quality is EXCELLENT!!! üòç Bought o...  Positive   \n",
       "1           2  Worst experience EVER!!! üò° totally disappointe...  Negative   \n",
       "2           3     The service was OKAY, nothing special #average   Neutral   \n",
       "3           4   I LOVE this product <b>Highly Recommended</b> üëçüëç  Positive   \n",
       "4           5  Very poor customer support @supportteam, delay...  Negative   \n",
       "5           6      <p>Average performance</p> could be BETTER!!!   Neutral   \n",
       "6           7          Absolutely FANTASTIC!!! üòçüî• #HappyCustomer  Positive   \n",
       "7           8                 Not worth the money I paid 5000‚Çπ üò†  Negative   \n",
       "8           9  The app works fine BUT sometimes crashes @devteam   Neutral   \n",
       "9          10  Great VALUE for money üí∞ Fast delivery on 2024-...  Positive   \n",
       "10         11           Terrible packaging!!! damaged product üò°üò°  Negative   \n",
       "11         12  The product does WHAT it claims <xml>verified<...   Neutral   \n",
       "12         13             Amazing experience üòä Will BUY again!!!  Positive   \n",
       "13         14              Completely USELESS and frustrating üò§üò§  Negative   \n",
       "14         15               Neither good NOR bad, just okay... ü§∑   Neutral   \n",
       "15         16  Customer service was VERY helpful & polite @he...  Positive   \n",
       "16         17      Bad quality material!!! broke within 3 days üòû  Negative   \n",
       "17         18  The design is decent BUT functionality is LIMI...   Neutral   \n",
       "18         19  Extremely satisfied with the purchase üòç #Satis...  Positive   \n",
       "19         20  Regret buying this üò° Very disappointing!!! Ord...  Negative   \n",
       "\n",
       "                        Email_ID  \n",
       "0         vamshi.kumar@gmail.com  \n",
       "1          rockstar_99@yahoo.com  \n",
       "2         data.learner@gmail.com  \n",
       "3        ml.engineer@outlook.com  \n",
       "4         support.user@yahoo.com  \n",
       "5        analytics.pro@gmail.com  \n",
       "6       happy.customer@gmail.com  \n",
       "7         budget.buyer@yahoo.com  \n",
       "8         app.tester@outlook.com  \n",
       "9        fast.delivery@gmail.com  \n",
       "10          angry.user@yahoo.com  \n",
       "11    verified.buyer@outlook.com  \n",
       "12     repeat.customer@gmail.com  \n",
       "13     frustrated.user@yahoo.com  \n",
       "14    neutral.reviewer@gmail.com  \n",
       "15   polite.customer@outlook.com  \n",
       "16       quality.issue@yahoo.com  \n",
       "17     design.reviewer@gmail.com  \n",
       "18    satisfied.user@outlook.com  \n",
       "19  disappointed.buyer@yahoo.com  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Review_ID\": range(1, 21),\n",
    "    \"Review_Text\": [\n",
    "        \"The PRODUCT quality is EXCELLENT!!! üòç Bought on 12-01-2024 at 10:30AM\",\n",
    "        \"Worst experience EVER!!! üò° totally disappointed... visit http://badreviews.com\",\n",
    "        \"The service was OKAY, nothing special #average\",\n",
    "        \"I LOVE this product <b>Highly Recommended</b> üëçüëç\",\n",
    "        \"Very poor customer support @supportteam, delayed delivery üòû\",\n",
    "        \"<p>Average performance</p> could be BETTER!!!\",\n",
    "        \"Absolutely FANTASTIC!!! üòçüî• #HappyCustomer\",\n",
    "        \"Not worth the money I paid 5000‚Çπ üò†\",\n",
    "        \"The app works fine BUT sometimes crashes @devteam\",\n",
    "        \"Great VALUE for money üí∞ Fast delivery on 2024-05-10\",\n",
    "        \"Terrible packaging!!! damaged product üò°üò°\",\n",
    "        \"The product does WHAT it claims <xml>verified</xml>\",\n",
    "        \"Amazing experience üòä Will BUY again!!!\",\n",
    "        \"Completely USELESS and frustrating üò§üò§\",\n",
    "        \"Neither good NOR bad, just okay... ü§∑\",\n",
    "        \"Customer service was VERY helpful & polite @helpdesk\",\n",
    "        \"Bad quality material!!! broke within 3 days üòû\",\n",
    "        \"The design is decent BUT functionality is LIMITED #design\",\n",
    "        \"Extremely satisfied with the purchase üòç #Satisfied\",\n",
    "        \"Regret buying this üò° Very disappointing!!! OrderID: 12345\"\n",
    "    ],\n",
    "    \"Sentiment\": [\n",
    "        \"Positive\", \"Negative\", \"Neutral\", \"Positive\", \"Negative\",\n",
    "        \"Neutral\", \"Positive\", \"Negative\", \"Neutral\", \"Positive\",\n",
    "        \"Negative\", \"Neutral\", \"Positive\", \"Negative\", \"Neutral\",\n",
    "        \"Positive\", \"Negative\", \"Neutral\", \"Positive\", \"Negative\"\n",
    "    ],\n",
    "    \"Email_ID\": [\n",
    "        \"vamshi.kumar@gmail.com\",\n",
    "        \"rockstar_99@yahoo.com\",\n",
    "        \"data.learner@gmail.com\",\n",
    "        \"ml.engineer@outlook.com\",\n",
    "        \"support.user@yahoo.com\",\n",
    "        \"analytics.pro@gmail.com\",\n",
    "        \"happy.customer@gmail.com\",\n",
    "        \"budget.buyer@yahoo.com\",\n",
    "        \"app.tester@outlook.com\",\n",
    "        \"fast.delivery@gmail.com\",\n",
    "        \"angry.user@yahoo.com\",\n",
    "        \"verified.buyer@outlook.com\",\n",
    "        \"repeat.customer@gmail.com\",\n",
    "        \"frustrated.user@yahoo.com\",\n",
    "        \"neutral.reviewer@gmail.com\",\n",
    "        \"polite.customer@outlook.com\",\n",
    "        \"quality.issue@yahoo.com\",\n",
    "        \"design.reviewer@gmail.com\",\n",
    "        \"satisfied.user@outlook.com\",\n",
    "        \"disappointed.buyer@yahoo.com\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166aced-0d25-4523-bf2f-bad0699fccef",
   "metadata": {},
   "source": [
    "# Check whether the text is in lower or upper or (lower and upper) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5aa3375-a0e8-4a6c-8d9e-72d43485d562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check  whether the data is in upper or lower\n",
    "df['Review_Text'].apply(lambda x: True if x.islower() or x.isupper() else False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "192b4cc9-9b6c-4f02-adfc-162b2fdc4afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether the data is a combination of upper and lower\n",
    "df['Review_Text'].apply(lambda x: False if x.islower() or x.isupper() else True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b9d85-632c-4949-9a58-e6c94e47d93d",
   "metadata": {},
   "source": [
    "# Check whether the text contains any xml or html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c6e6fe-8b41-4a8b-b9a3-aefbadf02702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_Text'].apply(lambda x:True if re.search(r'<.*?>',x) else False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3490a-4839-499e-af68-bdb35c0efdb7",
   "metadata": {},
   "source": [
    "# Check whether the text contains urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4085f998-ee68-432c-80d1-4cfc5d0ee581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_Text'].apply(lambda x:True if re.search(r'http[s]?://\\S+',x) else False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3aa3a-569f-4703-b305-d59fe16affe7",
   "metadata": {},
   "source": [
    "# Check whether the text data contains any email ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "273a0d04-4cdb-4ba4-8554-3c455bdd6bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Email_ID'].apply(lambda x: True if re.search(r'\\S+@\\S+',x) else False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e32b917-cb24-419b-9669-1440f012ecc0",
   "metadata": {},
   "source": [
    "# Check whether the text data contains any mentions/hastags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39ea9aad-c2fb-4bda-8a10-2928846404ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_Text'].apply(lambda x: True if re.search(r'\\B[@#]\\S+',x) else False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8a788-7311-40ef-962e-04f8e50ac289",
   "metadata": {},
   "source": [
    "# Check whether the text data contains any emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62a8b4cb-6cd4-4abb-bbbc-8ab042e8e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6d0c1e0-1501-4cde-ac59-5d8a97ce9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Absolutely FANTASTIC!!! üòçüî• #HappyCustomer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d364790f-2b95-4418-a7eb-427941a59d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emoji_count(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31e3248f-7d5a-47dd-a52a-f83fbd12e68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely FANTASTIC!!! :smiling_face_with_heart-eyes::fire: #HappyCustomer'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.demojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e28c0985-9455-4a00-bf39-8a7d10a4f35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_Text'].apply(lambda x: True if emoji.emoji_count(x) else False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535bac2-ce4e-488d-b721-dfce9abc9fd2",
   "metadata": {},
   "source": [
    "# Check whether the text data contains any numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebd07b13-5db9-4a1b-b31a-1b0f74c17ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_Text'].apply(lambda x: True if re.search('\\d',x) else False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d02fce-ab5b-4d21-93a1-b2ab4da33666",
   "metadata": {},
   "source": [
    "# Check whether the text data contains any punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32e75cc8-9a08-46c7-9631-305b0dd6eba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b426e3fa-11a1-43b4-be5d-abb4ef5c019b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(18)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_Text'].apply(lambda x: True if re.search('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]',x)else False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b325ee5-2e40-4ffa-82d4-bf153f3fc96e",
   "metadata": {},
   "source": [
    "# Check whether the text data contains any date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09ccbdd6-0af6-4e04-ad06-55631b7e2b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_Text'].apply(lambda x: True if re.findall(r'\\d{1,2}-\\d{1,2}-\\d{4}', x) else False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7111d33-bdfa-4d69-860d-8d65c4b6d137",
   "metadata": {},
   "source": [
    "# Simple Eda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c4f7ca4c-3260-4b74-b171-d4ceb38c7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_eda(data,column):\n",
    "    import emoji\n",
    "    lower_upper=data[column].apply(lambda x: False if x.islower() or x.isupper() else True).sum()\n",
    "    html_xml=data[column].apply(lambda x:True if re.search(r'<.*?>',x) else False).sum()\n",
    "    urls=data[column].apply(lambda x:True if re.search(r'http[s]?://\\S+',x) else False).sum()\n",
    "    emails=data[column].apply(lambda x: True if re.search(r'\\S+@\\S+',x) else False).sum()\n",
    "    mentions_hastags=data[column].apply(lambda x: True if re.search(r'\\B[@#]\\S+',x) else False).sum()\n",
    "    emo=data[column].apply(lambda x: True if emoji.emoji_count(x) else False).sum()\n",
    "    digits=data[column].apply(lambda x: True if re.search('\\d',x) else False).sum()\n",
    "    punctuations=data[column].apply(lambda x: True if re.search('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]',x)else False).sum()\n",
    "    date=data[column].apply(lambda x: True if re.findall(r'\\d{1,2}-\\d{1,2}-\\d{4}', x) else False).sum()\n",
    "    missing_values=data[column].isna().sum()\n",
    "    duplicates=data[column].duplicated().sum()\n",
    "\n",
    "    if lower_upper>0:\n",
    "        print(f'The {column} contains the both lower and upper cases')\n",
    "    if html_xml>0:\n",
    "        print(f'The {column} contains the xml or html tags')\n",
    "    if urls>0:\n",
    "        print(f'The {column} contains urls')\n",
    "    if emails>0:\n",
    "        print(f'The {column} contains emails')\n",
    "    if mentions_hastags>0:\n",
    "        print(f'The {column} contains mentions and hastags')\n",
    "    if emo>0:\n",
    "        print(f'The {column} contains emojis')\n",
    "    if digits>0:\n",
    "        print(f'The {column} contains digits')\n",
    "    if punctuations>0:\n",
    "        print(f'The {column} contains Punctuations')\n",
    "    if date>0:\n",
    "        print(f'The {column} contains date')\n",
    "    if missing_values>0:\n",
    "        print(f'The {column} has {missing_values} missing values')\n",
    "    if duplicates>0:\n",
    "        print(f'The {column} has {duplicates} duplicate values')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42483958-9b92-4170-a8cc-c653a59e40d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Palestinians switch off Christmas lights in Be...</td>\n",
       "      <td>RAMALLAH, West Bank (Reuters) - Palestinians s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>China says Trump call with Taiwan president wo...</td>\n",
       "      <td>BEIJING (Reuters) - U.S. President-elect Donal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FAIL! The Trump Organization‚Äôs Credit Score W...</td>\n",
       "      <td>While the controversy over Trump s personal ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Zimbabwe military chief's China trip was norma...</td>\n",
       "      <td>BEIJING (Reuters) - A trip to Beijing last wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>THE MOST UNCOURAGEOUS PRESIDENT EVER Receives ...</td>\n",
       "      <td>There has never been a more UNCOURAGEOUS perso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>24348</td>\n",
       "      <td>Mexico Senate committee OK's air transport dea...</td>\n",
       "      <td>MEXICO CITY (Reuters) - A key committee in Mex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>24349</td>\n",
       "      <td>BREAKING: HILLARY CLINTON‚ÄôS STATE DEPARTMENT G...</td>\n",
       "      <td>IF SHE S NOT TOAST NOW THEN WE RE IN BIGGER TR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>24350</td>\n",
       "      <td>trump breaks from stump speech to admire beaut...</td>\n",
       "      <td>kremlin nato was created for agression&nbsp;&nbsp;\\nruss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>24351</td>\n",
       "      <td>NFL PLAYER Delivers Courageous Message: Stop B...</td>\n",
       "      <td>Dallas Cowboys star wide receiver Dez Bryant t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>24352</td>\n",
       "      <td>NORDSTROM STOCK TAKES NOSEDIVE After Trump Twe...</td>\n",
       "      <td>UPDATE: Nordstrom stock closed up slightly tod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24353 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0               0  Palestinians switch off Christmas lights in Be...   \n",
       "1               1  China says Trump call with Taiwan president wo...   \n",
       "2               2   FAIL! The Trump Organization‚Äôs Credit Score W...   \n",
       "3               3  Zimbabwe military chief's China trip was norma...   \n",
       "4               4  THE MOST UNCOURAGEOUS PRESIDENT EVER Receives ...   \n",
       "...           ...                                                ...   \n",
       "24348       24348  Mexico Senate committee OK's air transport dea...   \n",
       "24349       24349  BREAKING: HILLARY CLINTON‚ÄôS STATE DEPARTMENT G...   \n",
       "24350       24350  trump breaks from stump speech to admire beaut...   \n",
       "24351       24351  NFL PLAYER Delivers Courageous Message: Stop B...   \n",
       "24352       24352  NORDSTROM STOCK TAKES NOSEDIVE After Trump Twe...   \n",
       "\n",
       "                                                    text  label  \n",
       "0      RAMALLAH, West Bank (Reuters) - Palestinians s...      1  \n",
       "1      BEIJING (Reuters) - U.S. President-elect Donal...      1  \n",
       "2      While the controversy over Trump s personal ta...      0  \n",
       "3      BEIJING (Reuters) - A trip to Beijing last wee...      1  \n",
       "4      There has never been a more UNCOURAGEOUS perso...      0  \n",
       "...                                                  ...    ...  \n",
       "24348  MEXICO CITY (Reuters) - A key committee in Mex...      1  \n",
       "24349  IF SHE S NOT TOAST NOW THEN WE RE IN BIGGER TR...      0  \n",
       "24350  kremlin nato was created for agression  \\nruss...      0  \n",
       "24351  Dallas Cowboys star wide receiver Dez Bryant t...      0  \n",
       "24352  UPDATE: Nordstrom stock closed up slightly tod...      0  \n",
       "\n",
       "[24353 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\masir\\Downloads\\Machine Learning\\NLP\\train (2).csv\",on_bad_lines='skip',delimiter=';')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "909e7f8e-d7a1-411f-9761-84cbe8fcccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text contains the both lower and upper cases\n",
      "The text contains the xml or html tags\n",
      "The text contains urls\n",
      "The text contains emails\n",
      "The text contains mentions and hastags\n",
      "The text contains emojis\n",
      "The text contains digits\n",
      "The text contains Punctuations\n",
      "The text contains date\n"
     ]
    }
   ],
   "source": [
    "simple_eda(data,'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395d71e-7f67-4c5a-8c90-b440c6fd5f31",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f7ab9-30fd-425c-a50d-bce0e25a8fce",
   "metadata": {},
   "source": [
    "# Convert data into lower case or upper case (based on problem statment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0589993a-a9b6-404e-9aa4-73ba5ed6c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame({'Reviews':['I LOVE BIRYANI','I Love Biryani','i love biryani']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7117ddab-799e-4c4a-b5cb-7e373d9deb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I LOVE BIRYANI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Love Biryani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love biryani</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Reviews\n",
       "0  I LOVE BIRYANI\n",
       "1  I Love Biryani\n",
       "2  i love biryani"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d32c997-7222-4c8f-8ecb-949cca192ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i love biryani\n",
       "1    i love biryani\n",
       "2    i love biryani\n",
       "Name: Reviews, dtype: str"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Reviews'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a88842bb-4649-4b0e-98ef-d759fe061eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I LOVE BIRYANI\n",
       "1    I LOVE BIRYANI\n",
       "2    I LOVE BIRYANI\n",
       "Name: Reviews, dtype: str"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Reviews'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273bb56-7d39-42d7-bc6f-9b47fae0c63c",
   "metadata": {},
   "source": [
    "# remove the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df78ce14-cd27-474b-a1d7-b4e85e25fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame({'Reviews':['<p>I LOVE BIRYANI</p>','<span><p>I Love Biryani</p></span>','<div>i love biryani</div>']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27d14997-a724-4889-8f65-c8640054ddc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I LOVE BIRYANI&lt;/p&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;span&gt;&lt;p&gt;I Love Biryani&lt;/p&gt;&lt;/span&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;div&gt;i love biryani&lt;/div&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Reviews\n",
       "0               <p>I LOVE BIRYANI</p>\n",
       "1  <span><p>I Love Biryani</p></span>\n",
       "2           <div>i love biryani</div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec302828-0d52-4e00-b2ef-c786393650b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I LOVE BIRYANI \n",
       "1      I Love Biryani  \n",
       "2       i love biryani \n",
       "Name: Reviews, dtype: str"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Reviews'].apply(lambda x: re.sub(r'<.*?>',' ',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da56708-71fc-4e21-99d4-65609de5d076",
   "metadata": {},
   "source": [
    "# remove any urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "689396ac-fdf1-4b0e-9d62-900250c94ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I LOVE BIRYANI i have order from https://swiggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Love Biryani i have orderd from https://Zomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love biryani i have orderd from http://pizza</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Reviews\n",
       "0   I LOVE BIRYANI i have order from https://swiggy\n",
       "1  I Love Biryani i have orderd from https://Zomato\n",
       "2    i love biryani i have orderd from http://pizza"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Reviews': [\n",
    "        'I LOVE BIRYANI i have order from https://swiggy',\n",
    "        'I Love Biryani i have orderd from https://Zomato',\n",
    "        'i love biryani i have orderd from http://pizza'\n",
    "    ]\n",
    "})\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27465bdd-160d-4745-8f6c-6155404699f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     I LOVE BIRYANI i have order from \n",
       "1    I Love Biryani i have orderd from \n",
       "2    i love biryani i have orderd from \n",
       "Name: Reviews, dtype: str"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Reviews'].apply(lambda x:re.sub(r'https?://\\S+','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c681cd7-07ed-40b3-8051-e5ea4a5c3714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I LOVE BIRYANI i have order from https:\\swiggy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Love Biryani i have orderd from https:\\ mail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love biryani i have orderd from http:\\pizza ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews\n",
       "0  I LOVE BIRYANI i have order from https:\\swiggy...\n",
       "1  I Love Biryani i have orderd from https:\\ mail...\n",
       "2  i love biryani i have orderd from http:\\pizza ..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Reviews': [\n",
    "        'I LOVE BIRYANI i have order from https:\\\\swiggy contact me at user1@gmail.com',\n",
    "        'I Love Biryani i have orderd from https:\\\\ mail id is foodie@yahoo.com',\n",
    "        'i love biryani i have orderd from http:\\\\pizza reach me at test_user@outlook.com'\n",
    "    ]\n",
    "})\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8aa30e4b-1f98-461b-9912-30cf629f244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reviews']=data['Reviews'].apply(lambda x:re.sub(r'\\S+@+\\S+','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "50537ab5-b15a-48e8-951c-ff5063f2c6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I LOVE BIRYANI i have order from https:\\\\swiggy contact me at '"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0,'Reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057f0e9-2337-4bac-a3a4-307eb10ba89d",
   "metadata": {},
   "source": [
    "# remove mentions and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66ed59a4-f664-4d37-bc0f-1fa1f5d31722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love biryani&nbsp;&nbsp;@swiggy_support #food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I LOVE biryani&nbsp;&nbsp;@zomato_care #biryani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love biryani&nbsp;&nbsp;@pizza_help #hungry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Reviews\n",
       "0  I love biryani  @swiggy_support #food\n",
       "1  I LOVE biryani  @zomato_care #biryani\n",
       "2    i love biryani  @pizza_help #hungry"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Reviews': [\n",
    "        'I love biryani  @swiggy_support #food',\n",
    "        'I LOVE biryani  @zomato_care #biryani',\n",
    "        'i love biryani  @pizza_help #hungry'\n",
    "    ]\n",
    "})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f94a031-6516-48be-b750-e1bed0b312a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I love biryani   \n",
       "1    I LOVE biryani   \n",
       "2    i love biryani   \n",
       "Name: Reviews, dtype: str"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Reviews'].apply(lambda x: re.sub(r'\\B[@#]\\S+','',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f4535-f72a-4458-b075-ce91387ba0ae",
   "metadata": {},
   "source": [
    "# convert Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0c945e86-81e6-4998-97d4-192dfb7adfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "92a09168-ca38-4337-8c9b-bfe5d173e147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this product üòçüî• totally worth it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worst experience ever üò°üëé very disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is okay üôÇ nothing special but works fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazing quality and fast delivery üöÄüòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not happy with the service üòûüò§ will not recommend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Review_Text\n",
       "0          I love this product üòçüî• totally worth it!\n",
       "1        Worst experience ever üò°üëé very disappointed\n",
       "2       It is okay üôÇ nothing special but works fine\n",
       "3              Amazing quality and fast delivery üöÄüòä\n",
       "4  Not happy with the service üòûüò§ will not recommend"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Review_Text\": [\n",
    "        \"I love this product üòçüî• totally worth it!\",\n",
    "        \"Worst experience ever üò°üëé very disappointed\",\n",
    "        \"It is okay üôÇ nothing special but works fine\",\n",
    "        \"Amazing quality and fast delivery üöÄüòä\",\n",
    "        \"Not happy with the service üòûüò§ will not recommend\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b4eaeb2-afba-492c-a0d0-276e70675418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I love this product smiling_face_with_heart-ey...\n",
       "1    Worst experience ever enraged_facethumbs_down ...\n",
       "2    It is okay slightly_smiling_face nothing speci...\n",
       "3    Amazing quality and fast delivery rocketsmilin...\n",
       "4    Not happy with the service disappointed_facefa...\n",
       "Name: Review_Text, dtype: str"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_Text'].apply(lambda x:emoji.demojize(x,delimiters=('','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec87faf-eb92-4f6b-881f-fdda433d3200",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab97ea33-bd5f-4de1-a48f-20d98c09386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9374fc-6b96-40cb-ae96-6b8c45e76404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albanian',\n",
       " 'arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'belarusian',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'tamil',\n",
       " 'turkish',\n",
       " 'uzbek']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26fb6d37-25b6-443d-834e-bc8c8b5d9e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27e6b5b-add1-4d96-900d-2e352bef7e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a5c0e-59d5-4bd4-ae0b-ddaac8c8e074",
   "metadata": {},
   "source": [
    "# Sentence Tokenization & Word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ebd526-c60b-40a4-9aaa-a1f4f1d75dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8629d73-970e-40f5-a162-0322acb8197a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love biryani.', 'It is very tasty!', 'Do you like it?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love biryani. It is very tasty! Do you like it?\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f929bc-55cf-4646-9025-2bbb83a89209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'biryani', '!', 'It', 'is', 'very', 'tasty', 'üòä']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love biryani! It is very tasty üòä\"\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3ac5f-e5f2-46a6-8f08-a163f027a7ef",
   "metadata": {},
   "source": [
    "# Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7536343-a09d-4d83-90fb-da54874c7483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love biryani and it was delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The biryani was not very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I did not like the taste of the food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the best biryani that I have eaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was an average meal and it was okay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Review\n",
       "0         I love biryani and it was delicious\n",
       "1               The biryani was not very good\n",
       "2        I did not like the taste of the food\n",
       "3  This is the best biryani that I have eaten\n",
       "4      It was an average meal and it was okay"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    \"Review\": [\n",
    "        \"I love biryani and it was delicious\",\n",
    "        \"The biryani was not very good\",\n",
    "        \"I did not like the taste of the food\",\n",
    "        \"This is the best biryani that I have eaten\",\n",
    "        \"It was an average meal and it was okay\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7c58a4-58fa-49c7-8aa8-d64a44baef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordslist=stopwords.words('english')\n",
    "stopwordslist.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82bbb272-2eac-4d9f-b65b-909fb9034ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,doc in enumerate(data['Review']):\n",
    "    doc1=[]\n",
    "    for token in word_tokenize(doc):\n",
    "        if token.lower() not in stopwordslist:\n",
    "            doc1.append(token)\n",
    "    data.loc[i,'Review']=' '.join(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc8c020a-298a-4ae6-88fe-b70c962b6c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love biryani delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biryani not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not like taste food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best biryani eaten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>average meal okay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Review\n",
       "0  love biryani delicious\n",
       "1        biryani not good\n",
       "2     not like taste food\n",
       "3      best biryani eaten\n",
       "4       average meal okay"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcdf79-0666-49eb-9473-16515fadde77",
   "metadata": {},
   "source": [
    "# Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24b8396-5190-4f21-a786-0155d2bd9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "284155cb-be51-4357-8638-1f4d89d19a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cannot believe it is not good'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I can't believe it's not good\"\n",
    "contractions.fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0815625f-72fb-42cc-a059-109e9ae7066c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe the food isn't good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm happy with the service but it hasn't arrived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They've delivered late and I don't like it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's okay but I won't order again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We didn't enjoy the meal and it's overpriced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review\n",
       "0               I can't believe the food isn't good\n",
       "1  I'm happy with the service but it hasn't arrived\n",
       "2        They've delivered late and I don't like it\n",
       "3                 It's okay but I won't order again\n",
       "4      We didn't enjoy the meal and it's overpriced"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Review\": [\n",
    "        \"I can't believe the food isn't good\",\n",
    "        \"I'm happy with the service but it hasn't arrived\",\n",
    "        \"They've delivered late and I don't like it\",\n",
    "        \"It's okay but I won't order again\",\n",
    "        \"We didn't enjoy the meal and it's overpriced\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4cbda7f-ddc0-4116-a817-31f92578372c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                I cannot believe the food is not good\n",
       "1    I am happy with the service but it has not arr...\n",
       "2        They have delivered late and I do not like it\n",
       "3                It is okay but I will not order again\n",
       "4       We did not enjoy the meal and it is overpriced\n",
       "Name: Review, dtype: str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bfee9-6bce-410a-8d41-b81395360ed6",
   "metadata": {},
   "source": [
    "# acronyms of chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "365200b9-a8c4-4535-9b79-fa740ea4a777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chat_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOL that biryani was amazing üòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRB ordering food rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDK why the delivery is late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMG this app is so slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYI the order was canceled smh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Chat_Text\n",
       "0  LOL that biryani was amazing üòÇ\n",
       "1            BRB ordering food rn\n",
       "2    IDK why the delivery is late\n",
       "3         OMG this app is so slow\n",
       "4  FYI the order was canceled smh"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Chat_Text\": [\n",
    "        \"LOL that biryani was amazing üòÇ\",\n",
    "        \"BRB ordering food rn\",\n",
    "        \"IDK why the delivery is late\",\n",
    "        \"OMG this app is so slow\",\n",
    "        \"FYI the order was canceled smh\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51b85b51-ca7c-4528-896c-3062476c463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acronyms = {\n",
    "    \"LOL\": \"laugh out loud\",\n",
    "    \"BRB\": \"be right back\",\n",
    "    \"RN\": \"right now\",\n",
    "    \"IDK\": \"i do not know\",\n",
    "    \"OMG\": \"oh my god\",\n",
    "    \"FYI\": \"for your information\",\n",
    "    \"SMH\": \"shaking my head\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52296fe4-243f-44ca-8342-dc4a3f12003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,doc in enumerate(df['Chat_Text']):\n",
    "    doc1=[]\n",
    "    for token in word_tokenize(doc):\n",
    "        if token in acronyms:\n",
    "            doc1.append(acronyms[token])\n",
    "        else:\n",
    "            doc1.append(token)\n",
    "    df.loc[i,'Chat_Text']=' '.join(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3aefbbcd-2cd6-41c3-8037-d6e5ef70c8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chat_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>laugh out loud that biryani was amazing üòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be right back ordering food rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i do not know why the delivery is late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oh my god this app is so slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your information the order was canceled smh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Chat_Text\n",
       "0        laugh out loud that biryani was amazing üòÇ\n",
       "1                   be right back ordering food rn\n",
       "2           i do not know why the delivery is late\n",
       "3                    oh my god this app is so slow\n",
       "4  for your information the order was canceled smh"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646afd17-00f2-44e5-b8ee-6878930a5bfe",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbc91348-47d5-49da-8d31-782eae743c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Sentence\n",
      "0  The children are playing in the gardens.\n",
      "1     She studies harder than her brothers.\n",
      "2      They were running towards the buses.\n",
      "3       He played better matches last year.\n",
      "4           The cats were chasing the mice.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Sentence\": [\n",
    "        \"The children are playing in the gardens.\",\n",
    "        \"She studies harder than her brothers.\",\n",
    "        \"They were running towards the buses.\",\n",
    "        \"He played better matches last year.\",\n",
    "        \"The cats were chasing the mice.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec911a-9afc-4bdb-9255-ee9cfc0ba8b2",
   "metadata": {},
   "source": [
    "# PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc4a3447-2678-41fe-b8b6-36039a80692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8fe2187-caeb-4e96-99b1-e627d21c1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48e25937-4cb2-4f51-aa05-b7d1a1c07e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'programm'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('Programmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e97e431a-9acd-4d18-ab51-e8d151be32d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20e4490e-64c3-48da-8163-5a897cf77bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('Programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66d6a7ef-55a5-4f3d-b6f1-ec0dee86a33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happili'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('Happily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb510fae-09e4-4f92-9866-77502c26ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,doc in enumerate(df['Sentence']):\n",
    "    doc1=[]\n",
    "    for token in word_tokenize(doc):\n",
    "        doc1.append(ps.stem(token))\n",
    "    df.loc[i,'Sentence']=' '.join(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf67a0e5-b6ac-4443-b9cc-914ba52d96c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the children are play in the garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she studi harder than her brother .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they were run toward the buse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he play better match last year .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the cat were chase the mice .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Sentence\n",
       "0  the children are play in the garden .\n",
       "1    she studi harder than her brother .\n",
       "2        they were run toward the buse .\n",
       "3       he play better match last year .\n",
       "4          the cat were chase the mice ."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e0bb9-45f0-4cd3-b920-15050cd80c50",
   "metadata": {},
   "source": [
    "# SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e44d42-202f-4cd8-8492-89af5a65270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9256f6-6ce8-401d-abcc-7f926e380f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e6de948-55db-4866-93dc-62a6d8ee0bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'programm'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem('Programmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0dcfa4d-3368-4c84-93c3-a44775ec9eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4d5caa1-ce18-4df3-b8ae-743afaeb52f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem('Programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e1859f8-8e41-4214-9d91-8dac84d934bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happili'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem('Happily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd08e579-6a3b-4463-90ab-54e5d03bb33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Sentence\n",
      "0  The children are playing in the gardens.\n",
      "1     She studies harder than her brothers.\n",
      "2      They were running towards the buses.\n",
      "3       He played better matches last year.\n",
      "4           The cats were chasing the mice.\n",
      "                                Sentence\n",
      "0  the children are play in the garden .\n",
      "1    she studi harder than her brother .\n",
      "2        they were run toward the buse .\n",
      "3       he play better match last year .\n",
      "4          the cat were chase the mice .\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Sentence\": [\n",
    "        \"The children are playing in the gardens.\",\n",
    "        \"She studies harder than her brothers.\",\n",
    "        \"They were running towards the buses.\",\n",
    "        \"He played better matches last year.\",\n",
    "        \"The cats were chasing the mice.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "for i,doc in enumerate(df['Sentence']):\n",
    "    doc1=[]\n",
    "    for token in word_tokenize(doc):\n",
    "        doc1.append(ss.stem(token))\n",
    "    df.loc[i,'Sentence']=' '.join(doc1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e9a10-9533-45cc-9ff5-ffdfdafb8c3f",
   "metadata": {},
   "source": [
    "# LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d934e676-0d79-4be9-b4cf-f978fed39a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b015f20d-e85a-45b6-a54f-a600d90b7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "465ecdd0-a674-4f15-95ab-4de82bd45609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('Programmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd951a32-d22f-4584-be88-a7e160bc2c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('Running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a0e1d46-7888-4e31-9dd8-3b3975c969be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('Programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18f82a4d-eca6-40e6-946d-a5115d059bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('Happily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd3a7654-f1d0-45ff-822a-e6cb137fcdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Sentence\n",
      "0  The children are playing in the gardens.\n",
      "1     She studies harder than her brothers.\n",
      "2      They were running towards the buses.\n",
      "3       He played better matches last year.\n",
      "4           The cats were chasing the mice.\n",
      "                           Sentence\n",
      "0  the childr ar play in the gard .\n",
      "1   she study hard than her broth .\n",
      "2     they wer run toward the bus .\n",
      "3     he play bet match last year .\n",
      "4        the cat wer chas the mic .\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Sentence\": [\n",
    "        \"The children are playing in the gardens.\",\n",
    "        \"She studies harder than her brothers.\",\n",
    "        \"They were running towards the buses.\",\n",
    "        \"He played better matches last year.\",\n",
    "        \"The cats were chasing the mice.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "for i,doc in enumerate(df['Sentence']):\n",
    "    doc1=[]\n",
    "    for token in word_tokenize(doc):\n",
    "        doc1.append(ls.stem(token))\n",
    "    df.loc[i,'Sentence']=' '.join(doc1)\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ce0d3-d092-443d-a627-8f8d74022e62",
   "metadata": {},
   "source": [
    "# Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd6baa25-4baa-4833-b9f1-6462aa6eeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80d40260-f3e8-410e-aeea-0ea42ebdad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95b6e9b7-f538-4525-8bda-d5761e44fce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize('cats') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38f45761-f3a1-4acb-8f5c-c219eb7366e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize('running',pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69510ba9-ec54-4a00-be39-e899aba464f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize('better',pos='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3c83b22-7782-49e6-9f5f-27345c7af237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'faithfully'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize('faithfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a878ee5c-0e39-45fa-80a2-cff4ba16a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Sentence\n",
      "0  The children are playing in the gardens.\n",
      "1     She studies harder than her brothers.\n",
      "2      They were running towards the buses.\n",
      "3       He played better matches last year.\n",
      "4           The cats were chasing the mice.\n",
      "                                Sentence\n",
      "0  The child are playing in the garden .\n",
      "1    She study harder than her brother .\n",
      "2    They were running towards the bus .\n",
      "3     He played better match last year .\n",
      "4       The cat were chasing the mouse .\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Sentence\": [\n",
    "        \"The children are playing in the gardens.\",\n",
    "        \"She studies harder than her brothers.\",\n",
    "        \"They were running towards the buses.\",\n",
    "        \"He played better matches last year.\",\n",
    "        \"The cats were chasing the mice.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "for i,doc in enumerate(df['Sentence']):\n",
    "    doc1=[]\n",
    "    for token in word_tokenize(doc):\n",
    "        doc1.append(wl.lemmatize(token))\n",
    "    df.loc[i,'Sentence']=' '.join(doc1)\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa3e7c-e596-480e-b543-eab37d97f490",
   "metadata": {},
   "source": [
    "# Data Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "cfefda73-4742-46d8-ab83-91aa2970ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(data,column,case='lower',tags=True,urls=True,mentions_hashtags=True,digits=True,dates=True,Contractions=True,stop_wordss=True,inflections='stem',stems='porter',emoji=True,emails=True,punctuations=True):\n",
    "    import emoji\n",
    "    import contractions\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import pandas\n",
    "    from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer,WordNetLemmatizer\n",
    "    import re\n",
    "    ps=PorterStemmer()\n",
    "    ss=SnowballStemmer('english')\n",
    "    ls=LancasterStemmer()\n",
    "    wl=WordNetLemmatizer()\n",
    "    \n",
    "    stop_words=stopwords.words('english')\n",
    "    stop_words.remove('not')\n",
    "\n",
    "    \n",
    "\n",
    "    if emoji==True:\n",
    "        data[column]=data[column].apply(lambda x:emoji.demojize(x,delimiters=('','')))\n",
    "    \n",
    "    if case=='lower':\n",
    "        data[column]=data[column].str.lower()\n",
    "    elif case == 'upper':\n",
    "        data[column]=data[column].str.upper()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if tags==True:\n",
    "        data[column]=data[column].apply(lambda x: re.sub(r'<.*?>',' ',x))\n",
    "\n",
    "    if urls==True:\n",
    "        data[column]=data[column].apply(lambda x:re.sub(r'https?://\\S*','',x))\n",
    "\n",
    "    if mentions_hashtags==True:\n",
    "        data[column]=data[column].apply(lambda x: re.sub(r'\\B[@#]\\S+','',x))\n",
    "        \n",
    "    if dates==True:\n",
    "        data[column]=data[column].apply(lambda x: re.sub(r'\\d{1,2}-\\d{1,2}-\\d{4}',' ', x))\n",
    "        data[column]=data[column].apply(lambda x: re.sub(r'\\d{1,2}/\\d{1,2}/\\d{4}',' ', x))\n",
    "\n",
    "    if digits==True:\n",
    "        data[column]=data[column].apply(lambda x: re.sub(r'\\d','',x))\n",
    "\n",
    "    if Contractions==True:\n",
    "        data[column]=data[column].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "\n",
    "    if emails==True:\n",
    "        data[column]=data[column].apply(lambda x: re.sub(r'\\S+@\\S+','',x))\n",
    "\n",
    "    def stop(data,column):\n",
    "        l2=[]\n",
    "        for doc in data[column]:\n",
    "            l1=[]\n",
    "            for token in word_tokenize(doc):\n",
    "                if token.lower() not in stop_words:\n",
    "                    l1.append(token)\n",
    "            l2.append(' '.join(l1))\n",
    "        return l2\n",
    "    if stop_wordss==True:\n",
    "        data[column]=stop(data,column)\n",
    "\n",
    "\n",
    "    if inflections=='stem':\n",
    "        for i,doc in enumerate(data[column]):\n",
    "            l1=[]\n",
    "            for token in word_tokenize(doc):\n",
    "                if stems=='ps':\n",
    "                    word=ps.stem(token)\n",
    "                    l1.append(word)\n",
    "                elif stems=='ss':\n",
    "                    word=ss.stem(token)\n",
    "                    l1.append(word)\n",
    "                elif stems=='ls':\n",
    "                    word=wl.stem(token)\n",
    "                    l1.append(word) \n",
    "            data.loc[i,column]=' '.join(l1)\n",
    "    elif inflections=='lemma':\n",
    "        for i,doc in enumerate(data[column]):\n",
    "            l1=[]\n",
    "            for token in word_tokenize(doc):\n",
    "                word=wl.lemmatize(token)\n",
    "            l1.append(word)\n",
    "            data.loc[i,column]=' '.join(l1)\n",
    "\n",
    "    if punctuations==True:\n",
    "        data[column]=data[column].apply(lambda x: re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]','',x))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f8fcf4ff-32e3-41b9-8c07-5a4bb193af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(r\"C:\\Users\\masir\\Downloads\\Machine Learning\\NLP\\train (2).csv\",on_bad_lines='skip',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "88d725fa-8399-4892-ac1c-d1b887735397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Palestinians switch off Christmas lights in Be...</td>\n",
       "      <td>RAMALLAH, West Bank (Reuters) - Palestinians s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>China says Trump call with Taiwan president wo...</td>\n",
       "      <td>BEIJING (Reuters) - U.S. President-elect Donal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FAIL! The Trump Organization‚Äôs Credit Score W...</td>\n",
       "      <td>While the controversy over Trump s personal ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Zimbabwe military chief's China trip was norma...</td>\n",
       "      <td>BEIJING (Reuters) - A trip to Beijing last wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>THE MOST UNCOURAGEOUS PRESIDENT EVER Receives ...</td>\n",
       "      <td>There has never been a more UNCOURAGEOUS perso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  Palestinians switch off Christmas lights in Be...   \n",
       "1           1  China says Trump call with Taiwan president wo...   \n",
       "2           2   FAIL! The Trump Organization‚Äôs Credit Score W...   \n",
       "3           3  Zimbabwe military chief's China trip was norma...   \n",
       "4           4  THE MOST UNCOURAGEOUS PRESIDENT EVER Receives ...   \n",
       "\n",
       "                                                text  label  \n",
       "0  RAMALLAH, West Bank (Reuters) - Palestinians s...      1  \n",
       "1  BEIJING (Reuters) - U.S. President-elect Donal...      1  \n",
       "2  While the controversy over Trump s personal ta...      0  \n",
       "3  BEIJING (Reuters) - A trip to Beijing last wee...      1  \n",
       "4  There has never been a more UNCOURAGEOUS perso...      0  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c034c625-559f-43fb-861c-4fdce4879b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text contains the both lower and upper cases\n",
      "The text contains the xml or html tags\n",
      "The text contains urls\n",
      "The text contains emails\n",
      "The text contains mentions and hastags\n",
      "The text contains emojis\n",
      "The text contains digits\n",
      "The text contains Punctuations\n",
      "The text contains date\n",
      "The text has 1 duplicate values\n"
     ]
    }
   ],
   "source": [
    "simple_eda(data1,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7f226a76-f5ac-47d4-8fea-02f0f1e59f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Palestinians switch off Christmas lights in Be...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>China says Trump call with Taiwan president wo...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FAIL! The Trump Organization‚Äôs Credit Score W...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Zimbabwe military chief's China trip was norma...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>THE MOST UNCOURAGEOUS PRESIDENT EVER Receives ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>24348</td>\n",
       "      <td>Mexico Senate committee OK's air transport dea...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>24349</td>\n",
       "      <td>BREAKING: HILLARY CLINTON‚ÄôS STATE DEPARTMENT G...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24350</th>\n",
       "      <td>24350</td>\n",
       "      <td>trump breaks from stump speech to admire beaut...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24351</th>\n",
       "      <td>24351</td>\n",
       "      <td>NFL PLAYER Delivers Courageous Message: Stop B...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>24352</td>\n",
       "      <td>NORDSTROM STOCK TAKES NOSEDIVE After Trump Twe...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24353 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title text  \\\n",
       "0               0  Palestinians switch off Christmas lights in Be...        \n",
       "1               1  China says Trump call with Taiwan president wo...        \n",
       "2               2   FAIL! The Trump Organization‚Äôs Credit Score W...        \n",
       "3               3  Zimbabwe military chief's China trip was norma...        \n",
       "4               4  THE MOST UNCOURAGEOUS PRESIDENT EVER Receives ...        \n",
       "...           ...                                                ...  ...   \n",
       "24348       24348  Mexico Senate committee OK's air transport dea...        \n",
       "24349       24349  BREAKING: HILLARY CLINTON‚ÄôS STATE DEPARTMENT G...        \n",
       "24350       24350  trump breaks from stump speech to admire beaut...        \n",
       "24351       24351  NFL PLAYER Delivers Courageous Message: Stop B...        \n",
       "24352       24352  NORDSTROM STOCK TAKES NOSEDIVE After Trump Twe...        \n",
       "\n",
       "       label  \n",
       "0          1  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  \n",
       "...      ...  \n",
       "24348      1  \n",
       "24349      0  \n",
       "24350      0  \n",
       "24351      0  \n",
       "24352      0  \n",
       "\n",
       "[24353 rows x 4 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processing(data1,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d8533-bb9a-4f32-a31c-fe831c980847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
